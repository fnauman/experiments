---
title: Testing LLMs with Prompt Examples
author: Farrukh Nauman
date: April 20th, 2024
---

# Introduction

This document serves as a collection of prompt examples for testing Language Model Models (LLMs). Some prompts are single-turn questions about generating a code example or writing, while others are about structured output. For structured output, some models apparently call the API "multiple" times to ensure the output is structured. This is called the "function calling" mode. The way models are trained for function calling and tool use is with the aid of special tokens. 

## Function Calling

[Gorilla function calling leaderboard](https://github.com/ShishirPatil/gorilla/blob/main/berkeley-function-call-leaderboard/model_handler/constant.py)

```
    SYSTEM_PROMPT_FOR_CHAT_MODEL = """
        You are an expert in composing functions. You are given a question and a set of possible functions. 
        Based on the question, you will need to make one or more function/tool calls to achieve the purpose. 
        If none of the function can be used, point it out. If the given question lacks the parameters required by the function,
        also point it out. You should only return the function call in tools call sections.
        """

    USER_PROMPT_FOR_CHAT_MODEL = """
        Questions:{user_prompt}\nHere is a list of functions in JSON format that you can invoke:\n{functions}. 
        Should you decide to return the function call(s),Put it in the format of [func1(params_name=params_value, params_name2=params_value2...), func2(params)]\n
        NO other text MUST be included. 
        """
```


## Prompt Example 1: Clothing item description based on (GPT4-Vision)


The following was used for the demo.

```python
import base64
from enum import Enum
from typing import Iterable, Literal, Optional, List
from pydantic import BaseModel, Field

from openai import OpenAI
from dotenv import load_dotenv
import gradio as gr
from copy import copy

load_dotenv()

def encode_image(image: gr.Image):
    # Convert the gradio.Image to a PIL.Image
    # pil_image = Image.fromarray(image)
    pil_image = copy(image)
    
    # Create a BytesIO object
    byte_arr = BytesIO()
    
    # Save the PIL.Image as jpeg to the BytesIO object
    pil_image.save(byte_arr, format='PNG')
    
    # Get the byte value of the BytesIO object
    byte_value = byte_arr.getvalue()
    
    # Encode the bytes as base64 and return the result
    return base64.b64encode(byte_value).decode('utf-8')
    

# Define the schema for the input data
class UsageEnum(str, Enum):
    """Defines the recommended use for the second hand clothing item at a sorting facility."""
    REUSE = "Reuse and Resell"
    EXPORT = "Export to developing countries for reuse"
    OTHER = "Recycle, Repair or Dispose"

class DamageEnum(str, Enum):
    """Describes the nature and intensity of damage to the clothing item."""
    NONE = "No damage, like new condition"
    LOW = "Light damage, minor wear and tear"
    HIGH = "Heavy damage, significant wear and tear"

class ClothingItem(BaseModel):
    """Characteristics of a second hand clothing item: Pattern, Style, Category, Type, and Usage."""
    usage: UsageEnum = Field(..., description="Recommended use for the clothing item") # Field(None, description="") was leading to usage=None 
    caption: str = Field(..., description="Description of the clothing item in a sentence")
    confidence_score: float = Field(..., description="The confidence score of the prediction of usage as a percentage")
    pattern: str = Field(..., description="Clothing patterns such as stripes, floral, or solid")
    damage: DamageEnum = Field(..., description="Characterizes the nature and intensity of damage to the clothing item")
    category: str = Field(..., description="Clothing category such as shirt, pants, or dress")
    type: str = Field(..., description="Clothing type such as men, women, or children")


def annotate_front_img(base64_img: str) -> ClothingItem:
    response = instructor.from_openai(OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))).chat.completions.create(
        model=MODEL, # 'gpt-4-turbo',
        response_model=ClothingItem, # EmployeeList,
        seed=SEED, 
        temperature=TEMPERATURE, 
        max_tokens=300, 
        messages=[
            {
                "role": "user",
                "content": 'Analyze the image of a clothing item to identify its attributes and recommend the optimal usage.',
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_img}", 
                            "detail": "low"
                        }
                    },
                ],
            }
        ],
    )
    return response

```


## Prompt Example 2: `torch` code for image + tabular data

You are an expert data scientist who has been asked to build a model that combines image and tabular data using PyTorch. Write a PyTorch code snippet that demonstrates how to create a neural network model that takes both image and tabular data as input. The model should have separate branches for processing the image and tabular data, and then combine the outputs before making a final prediction. The code should be modular and easy to understand. You can use any dummy data for this example. Make the code short, but do not skip any important steps.

## Prompt Example 3: Synthetic (CSV) data generation

Example from VSCODE day. [Tutorial](https://github.com/alfredodeza/synthetic-datasets/blob/main/examples/2-generate-data/example.ipynb)

```python
    content = """
    I have the following CSV data:

    name,region,variety,rating,notes
    3 Rings Reserve Shiraz 2004,"Barossa Valley, Barossa, South Australia, Australia",Red Wine,96.0,"Vintage Comments : Classic Barossa vintage conditions. An average wet Spring followed by extreme heat in early February. Occasional rainfall events kept the vines in good balance up to harvest in late March 2004. Very good quality coupled with good average yields. More than 30 months in wood followed by six months tank maturation of the blend prior to bottling, July 2007. "
    Abreu Vineyards Cappella 2007,"Napa Valley, California",Red Wine,96.0,"Cappella is a proprietary blend of two clones of Cabernet Sauvignon with Cabernet Franc, Petit Verdot and Merlot. The gravelly soil at Cappella produces fruit that is very elegant in structure. The resulting wine exhibits beautiful purity of fruit with fine grained and lengthy tannins. "
    Abreu Vineyards Cappella 2010,"Napa Valley, California",Red Wine,98.0,"Cappella is one of the oldest vineyard sites in St. Helena. Six acres that sit alongside a Catholic cemetery on the west side of town, it was first planted in 1869. In the 1980s the church asked David to tear out the old vines, then he watched as the land lay fallow for close to two decades. When he finally got the chance to replant, he jumped. He'd tasted fruit from Cappella in the 70s. He knew what kind of wine it could make. But that first replant was ill-fated thanks to diseased rootstock, and once again he was ripping out vines. “It took us six years before we had a crop. We could have ignored it, pulled the vines out one by one as they collapsed. But then we'd have all these different ripening patterns, which would impact consistency. It was an easy decision.”"

    I would like you to generate synthetic data based on this input. Produce me 10 more examples of data formatted for CSVs to augment datasets."""

    system = """Act as an API for generating synthetic data based on inputs. Provide output formatted for CSVs to augment datasets. Do not provide any other feedback, input, questions, or
    any other kind of text that will not be valid CSV based on the input received. When you reply, there is no need to provide the headers, just the data."""
    # Generate some output
    completion = client.chat.completions.create(
        model="LLaMA_CPP",
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": content}
        ]
    )
    print(completion.choices[0].message.content)
```

